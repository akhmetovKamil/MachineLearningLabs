{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Third Lab"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22749cfa902f36b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### importing required libs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca9079102742d9e2"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-26T21:53:18.404798Z",
     "start_time": "2024-02-26T21:53:18.386594Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from ultralytics import YOLO\n",
    "import cv2 as cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Downloading and preparing model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8a263eafd20c427"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8s summary (fused): 168 layers, 11156544 parameters, 0 gradients, 28.6 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"Dataset/yolov8s.pt\")\n",
    "model.fuse()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T21:53:19.538978Z",
     "start_time": "2024-02-26T21:53:18.417189Z"
    }
   },
   "id": "5c82be550bb1980d",
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tracking objects from a web camera and video files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd0bff1560486fcd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path = 'Dataset/video.mp4'\n",
    "# cap = cv.VideoCapture(path) # Tracking video file\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read() \n",
    "    results = model.track(frame, persist=True)\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv.imshow('frame', annotated_frame)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T21:53:19.635103Z",
     "start_time": "2024-02-26T21:53:19.549881Z"
    }
   },
   "id": "467517fe9ba8e3f9",
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculating the model predictions accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b1b23ebd751461b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/7 /Users/shayrmovich/Documents/projects/MachineLearningLabs/Dataset/images/0_15_15_15.png: 384x640 2 cats, 1330.7ms\n",
      "image 2/7 /Users/shayrmovich/Documents/projects/MachineLearningLabs/Dataset/images/1_15_15_0.jpg: 640x544 1 person, 1 cat, 1 teddy bear, 716.3ms\n",
      "image 3/7 /Users/shayrmovich/Documents/projects/MachineLearningLabs/Dataset/images/2_15_15_15_15.jpg: 448x640 3 cats, 604.5ms\n",
      "image 4/7 /Users/shayrmovich/Documents/projects/MachineLearningLabs/Dataset/images/3_15_15.jpg: 480x640 2 cats, 854.1ms\n",
      "image 5/7 /Users/shayrmovich/Documents/projects/MachineLearningLabs/Dataset/images/4_57_59_16.jpg: 640x640 1 dog, 1 couch, 1 bed, 838.4ms\n",
      "image 6/7 /Users/shayrmovich/Documents/projects/MachineLearningLabs/Dataset/images/5_15_15_15.jpg: 512x640 3 cats, 565.4ms\n",
      "image 7/7 /Users/shayrmovich/Documents/projects/MachineLearningLabs/Dataset/images/6_15_16.jpg: 576x640 1 cat, 1 dog, 571.8ms\n",
      "Speed: 6.7ms preprocess, 783.0ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "0_15_15_15.png image prediction accuracy is 66%\n",
      "1_15_15_0.jpg image prediction accuracy is 66%\n",
      "2_15_15_15_15.jpg image prediction accuracy is 75%\n",
      "3_15_15.jpg image prediction accuracy is 100%\n",
      "4_57_59_16.jpg image prediction accuracy is 100%\n",
      "5_15_15_15.jpg image prediction accuracy is 100%\n",
      "6_15_16.jpg image prediction accuracy is 100%\n"
     ]
    }
   ],
   "source": [
    "results = model('Dataset/images/')\n",
    "for result in results:\n",
    "    prediction = result.boxes.cls.numpy()\n",
    "    real = os.path.basename(result.path).split('_')[1:]\n",
    "    real[-1] = real[-1].split('.')[0]\n",
    "    real = list(map(int, real))\n",
    "    intersection = Counter(real) & Counter(prediction)\n",
    "    accuracy = int((sum(intersection.values())/len(real) * 100))\n",
    "    print(f'{os.path.basename(result.path)} image prediction accuracy is {accuracy}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T21:56:33.313815Z",
     "start_time": "2024-02-26T21:56:27.639265Z"
    }
   },
   "id": "5fc3b8cc05631d98",
   "execution_count": 69
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
